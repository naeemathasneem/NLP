{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNEpWIwjQ01z+FTwrUaE/7U"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"ecmOz4n9STqy"},"outputs":[],"source":["import nltk"]},{"cell_type":"code","source":["help(nltk)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G8ELcJySTtfS","executionInfo":{"status":"ok","timestamp":1717220362652,"user_tz":-330,"elapsed":15,"user":{"displayName":"naimu samad","userId":"06085924539137588202"}},"outputId":"89083f93-7e24-4e81-9c69-049d33ad990d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Help on package nltk:\n","\n","NAME\n","    nltk\n","\n","DESCRIPTION\n","    The Natural Language Toolkit (NLTK) is an open source Python library\n","    for Natural Language Processing.  A free online book is available.\n","    (If you use the library for academic research, please cite the book.)\n","    \n","    Steven Bird, Ewan Klein, and Edward Loper (2009).\n","    Natural Language Processing with Python.  O'Reilly Media Inc.\n","    https://www.nltk.org/book/\n","    \n","    isort:skip_file\n","    \n","    @version: 3.8.1\n","\n","PACKAGE CONTENTS\n","    app (package)\n","    book\n","    ccg (package)\n","    chat (package)\n","    chunk (package)\n","    classify (package)\n","    cli\n","    cluster (package)\n","    collections\n","    collocations\n","    compat\n","    corpus (package)\n","    data\n","    decorators\n","    downloader\n","    draw (package)\n","    featstruct\n","    grammar\n","    help\n","    inference (package)\n","    internals\n","    jsontags\n","    langnames\n","    lazyimport\n","    lm (package)\n","    metrics (package)\n","    misc (package)\n","    parse (package)\n","    probability\n","    sem (package)\n","    sentiment (package)\n","    stem (package)\n","    tag (package)\n","    tbl (package)\n","    test (package)\n","    text\n","    tgrep\n","    tokenize (package)\n","    toolbox\n","    translate (package)\n","    tree (package)\n","    treeprettyprinter\n","    treetransforms\n","    twitter (package)\n","    util\n","    wsd\n","\n","SUBMODULES\n","    agreement\n","    aline\n","    api\n","    arlstem\n","    arlstem2\n","    association\n","    bleu_score\n","    bllip\n","    boxer\n","    brill\n","    brill_trainer\n","    casual\n","    chart\n","    chrf_score\n","    cistem\n","    confusionmatrix\n","    corenlp\n","    crf\n","    decisiontree\n","    dependencygraph\n","    destructive\n","    discourse\n","    distance\n","    drt\n","    earleychart\n","    evaluate\n","    featurechart\n","    gale_church\n","    gdfa\n","    gleu_score\n","    glue\n","    hmm\n","    hunpos\n","    ibm1\n","    ibm2\n","    ibm3\n","    ibm4\n","    ibm5\n","    ibm_model\n","    isri\n","    lancaster\n","    legality_principle\n","    lfg\n","    linearlogic\n","    logic\n","    mace\n","    malt\n","    mapping\n","    maxent\n","    megam\n","    meteor_score\n","    mwe\n","    naivebayes\n","    nist_score\n","    nonprojectivedependencyparser\n","    paice\n","    pchart\n","    perceptron\n","    phrase_based\n","    porter\n","    positivenaivebayes\n","    projectivedependencyparser\n","    prover9\n","    punkt\n","    recursivedescent\n","    regexp\n","    relextract\n","    repp\n","    resolution\n","    ribes_score\n","    rslp\n","    rte_classify\n","    scikitlearn\n","    scores\n","    segmentation\n","    senna\n","    sequential\n","    sexpr\n","    shiftreduce\n","    simple\n","    snowball\n","    sonority_sequencing\n","    spearman\n","    stack_decoder\n","    stanford\n","    stanford_segmenter\n","    tableau\n","    tadm\n","    textcat\n","    texttiling\n","    tnt\n","    toktok\n","    transitionparser\n","    treebank\n","    viterbi\n","    weka\n","    wordnet\n","\n","FUNCTIONS\n","    demo()\n","        # FIXME:  override any accidentally imported demo, see https://github.com/nltk/nltk/issues/2116\n","    \n","    tee(iterable, n=2, /)\n","        Returns a tuple of n independent iterators.\n","\n","DATA\n","    RUS_PICKLE = 'taggers/averaged_perceptron_tagger_ru/averaged_perceptro...\n","    SLASH = *slash*\n","    TYPE = *type*\n","    __author_email__ = 'nltk.team@gmail.com'\n","    __classifiers__ = ['Development Status :: 5 - Production/Stable', 'Int...\n","    __copyright__ = 'Copyright (C) 2001-2023 NLTK Project.\\n\\nDistribut......\n","    __keywords__ = ['NLP', 'CL', 'natural language processing', 'computati...\n","    __license__ = 'Apache License, Version 2.0'\n","    __longdescr__ = 'The Natural Language Toolkit (NLTK) is a Python ...NL...\n","    __maintainer__ = 'NLTK Team'\n","    __maintainer_email__ = 'nltk.team@gmail.com'\n","    __url__ = 'https://www.nltk.org/'\n","    app = <LazyModule 'nltk.app'>\n","    chat = <LazyModule 'nltk.chat'>\n","    corpus = <LazyModule 'nltk.corpus'>\n","    infile = <_io.TextIOWrapper name='/usr/local/lib/python3....packages/n...\n","    json_tags = {'!nltk.tag.BrillTagger': <class 'nltk.tag.brill.BrillTagg...\n","    toolbox = <LazyModule 'nltk.toolbox'>\n","    version_file = '/usr/local/lib/python3.10/dist-packages/nltk/VERSION'\n","\n","VERSION\n","    3.8.1\n","\n","AUTHOR\n","    NLTK Team\n","\n","FILE\n","    /usr/local/lib/python3.10/dist-packages/nltk/__init__.py\n","\n","\n"]}]},{"cell_type":"code","source":["nltk.download('stopwords')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VwdxLEPJVfLk","executionInfo":{"status":"ok","timestamp":1717220805416,"user_tz":-330,"elapsed":11,"user":{"displayName":"naimu samad","userId":"06085924539137588202"}},"outputId":"0937743c-2c23-4ff5-a091-94b84f3d4017"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["from nltk.corpus import stopwords\n","\n","stopwordss = stopwords.words(\"english\")"],"metadata":{"id":"-ESqevUjTy0n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["stopwordss"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rd1l1Yn9VRGZ","executionInfo":{"status":"ok","timestamp":1717220834592,"user_tz":-330,"elapsed":380,"user":{"displayName":"naimu samad","userId":"06085924539137588202"}},"outputId":"ff3065e9-b390-4061-83e4-23654227a12d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['i',\n"," 'me',\n"," 'my',\n"," 'myself',\n"," 'we',\n"," 'our',\n"," 'ours',\n"," 'ourselves',\n"," 'you',\n"," \"you're\",\n"," \"you've\",\n"," \"you'll\",\n"," \"you'd\",\n"," 'your',\n"," 'yours',\n"," 'yourself',\n"," 'yourselves',\n"," 'he',\n"," 'him',\n"," 'his',\n"," 'himself',\n"," 'she',\n"," \"she's\",\n"," 'her',\n"," 'hers',\n"," 'herself',\n"," 'it',\n"," \"it's\",\n"," 'its',\n"," 'itself',\n"," 'they',\n"," 'them',\n"," 'their',\n"," 'theirs',\n"," 'themselves',\n"," 'what',\n"," 'which',\n"," 'who',\n"," 'whom',\n"," 'this',\n"," 'that',\n"," \"that'll\",\n"," 'these',\n"," 'those',\n"," 'am',\n"," 'is',\n"," 'are',\n"," 'was',\n"," 'were',\n"," 'be',\n"," 'been',\n"," 'being',\n"," 'have',\n"," 'has',\n"," 'had',\n"," 'having',\n"," 'do',\n"," 'does',\n"," 'did',\n"," 'doing',\n"," 'a',\n"," 'an',\n"," 'the',\n"," 'and',\n"," 'but',\n"," 'if',\n"," 'or',\n"," 'because',\n"," 'as',\n"," 'until',\n"," 'while',\n"," 'of',\n"," 'at',\n"," 'by',\n"," 'for',\n"," 'with',\n"," 'about',\n"," 'against',\n"," 'between',\n"," 'into',\n"," 'through',\n"," 'during',\n"," 'before',\n"," 'after',\n"," 'above',\n"," 'below',\n"," 'to',\n"," 'from',\n"," 'up',\n"," 'down',\n"," 'in',\n"," 'out',\n"," 'on',\n"," 'off',\n"," 'over',\n"," 'under',\n"," 'again',\n"," 'further',\n"," 'then',\n"," 'once',\n"," 'here',\n"," 'there',\n"," 'when',\n"," 'where',\n"," 'why',\n"," 'how',\n"," 'all',\n"," 'any',\n"," 'both',\n"," 'each',\n"," 'few',\n"," 'more',\n"," 'most',\n"," 'other',\n"," 'some',\n"," 'such',\n"," 'no',\n"," 'nor',\n"," 'not',\n"," 'only',\n"," 'own',\n"," 'same',\n"," 'so',\n"," 'than',\n"," 'too',\n"," 'very',\n"," 's',\n"," 't',\n"," 'can',\n"," 'will',\n"," 'just',\n"," 'don',\n"," \"don't\",\n"," 'should',\n"," \"should've\",\n"," 'now',\n"," 'd',\n"," 'll',\n"," 'm',\n"," 'o',\n"," 're',\n"," 've',\n"," 'y',\n"," 'ain',\n"," 'aren',\n"," \"aren't\",\n"," 'couldn',\n"," \"couldn't\",\n"," 'didn',\n"," \"didn't\",\n"," 'doesn',\n"," \"doesn't\",\n"," 'hadn',\n"," \"hadn't\",\n"," 'hasn',\n"," \"hasn't\",\n"," 'haven',\n"," \"haven't\",\n"," 'isn',\n"," \"isn't\",\n"," 'ma',\n"," 'mightn',\n"," \"mightn't\",\n"," 'mustn',\n"," \"mustn't\",\n"," 'needn',\n"," \"needn't\",\n"," 'shan',\n"," \"shan't\",\n"," 'shouldn',\n"," \"shouldn't\",\n"," 'wasn',\n"," \"wasn't\",\n"," 'weren',\n"," \"weren't\",\n"," 'won',\n"," \"won't\",\n"," 'wouldn',\n"," \"wouldn't\"]"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["nltk.download('punkt')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nBohE5jVWnA_","executionInfo":{"status":"ok","timestamp":1717221100194,"user_tz":-330,"elapsed":429,"user":{"displayName":"naimu samad","userId":"06085924539137588202"}},"outputId":"1bc2f25b-15ce-41fd-d6ba-f4d2e4ac7165"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["sentence = \"hi, how are you, good morning\"\n","\n","tokens = nltk.word_tokenize(sentence)\n","\n","tokens"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_vXHkb8NVne1","executionInfo":{"status":"ok","timestamp":1717221125699,"user_tz":-330,"elapsed":400,"user":{"displayName":"naimu samad","userId":"06085924539137588202"}},"outputId":"13e80031-c704-446b-ff49-5bed80de5d7c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['hi', ',', 'how', 'are', 'you', ',', 'good', 'morning']"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","\n","sentence = \"hi, how are you, good morning\"\n","\n","stopwordss = set(stopwords.words(\"english\"))\n","\n","tokens = nltk.word_tokenize(sentence)\n","\n","tokens\n","\n","words = [w for w in tokens if not w in stopwordss]\n","\n","words"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NJYWdCTeWdT8","executionInfo":{"status":"ok","timestamp":1717221560801,"user_tz":-330,"elapsed":398,"user":{"displayName":"naimu samad","userId":"06085924539137588202"}},"outputId":"5dfc2364-cd1f-4222-a558-1df92696ca5c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['hi', ',', ',', 'good', 'morning']"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["sentence = \"Hi, How are you, Good morning\"\n","\n","stopwordss = set(stopwords.words(\"english\"))\n","\n","tokens = nltk.word_tokenize(sentence)\n","\n","tokens\n","\n","words = [w.lower() for w in tokens if not w in stopwordss]\n","\n","words"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Dx4_gweGYT7T","executionInfo":{"status":"ok","timestamp":1717222097621,"user_tz":-330,"elapsed":7,"user":{"displayName":"naimu samad","userId":"06085924539137588202"}},"outputId":"b3c64f0b-0090-458d-9131-f96ced7c7ee4"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['hi', ',', 'how', ',', 'good', 'morning']"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["# this is not good\n","\n","ngrams\n","\n","ngram = 1       ngram =2       ngram =3\n","\n","This            this is       this is not\n","is              is not        is not good\n","not             not good\n","good"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":106},"id":"VY2aSXeMaXKD","executionInfo":{"status":"error","timestamp":1717222329945,"user_tz":-330,"elapsed":15,"user":{"displayName":"naimu samad","userId":"06085924539137588202"}},"outputId":"ea68642b-f67f-4fb2-9b1f-bbaa8d7c1e49"},"execution_count":null,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"invalid syntax (<ipython-input-16-64725ae45434>, line 5)","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-16-64725ae45434>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    ngram = 1       ngram =2       ngram =3\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"]}]},{"cell_type":"code","source":["from nltk.util import ngrams\n","\n","sentence = \"Hi, How are you, Good morning\"\n","\n","Ngrams = ngrams(sequence = nltk.word_tokenize(sentence),n=3)\n","\n","for grams in Ngrams:\n","  print(grams)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WXQLr-BTbUjz","executionInfo":{"status":"ok","timestamp":1717222638779,"user_tz":-330,"elapsed":9,"user":{"displayName":"naimu samad","userId":"06085924539137588202"}},"outputId":"53545af9-a1c7-497a-c1cd-46e63f699a1b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["('Hi', ',', 'How')\n","(',', 'How', 'are')\n","('How', 'are', 'you')\n","('are', 'you', ',')\n","('you', ',', 'Good')\n","(',', 'Good', 'morning')\n"]}]},{"cell_type":"code","source":["from nltk.stem import SnowballStemmer\n","sb = SnowballStemmer(\"english\")\n","\n","words =['hi', 'programer', 'how', 'are', 'you', 'good', 'morning']\n","\n","for w in words:\n","  print(w,\",\",sb.stem(w))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BCUSwYVicf-w","executionInfo":{"status":"ok","timestamp":1717223093225,"user_tz":-330,"elapsed":486,"user":{"displayName":"naimu samad","userId":"06085924539137588202"}},"outputId":"b2339edb-d706-4749-fb93-2fd2a6445b5d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["hi , hi\n","programer , program\n","how , how\n","are , are\n","you , you\n","good , good\n","morning , morn\n"]}]},{"cell_type":"code","source":["from nltk.stem import PorterStemmer\n","porter = PorterStemmer()\n","\n","words =['hi', 'programer', 'how', 'was', 'you', 'good', 'morning']\n","print(\"word,porter stem\")\n","for w in words:\n","  print(w,\",\",porter.stem(w))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wsk4K8NIewHj","executionInfo":{"status":"ok","timestamp":1717223356377,"user_tz":-330,"elapsed":614,"user":{"displayName":"naimu samad","userId":"06085924539137588202"}},"outputId":"fd750b09-e6c7-4067-b0e6-9db54b2e3bc0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["word,porter stem\n","hi , hi\n","programer , program\n","how , how\n","was , wa\n","you , you\n","good , good\n","morning , morn\n"]}]},{"cell_type":"code","source":["nltk.download('wordnet')"],"metadata":{"id":"LEbJlvJyhn0b","executionInfo":{"status":"ok","timestamp":1717223988888,"user_tz":-330,"elapsed":10,"user":{"displayName":"naimu samad","userId":"06085924539137588202"}},"outputId":"3a01b063-2b5b-41cd-8453-e097039077eb","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["from nltk.stem import WordNetLemmatizer\n","\n","lem = WordNetLemmatizer()\n","\n","#lemmatize as nouns (default behavior)\n","print(\"rocks as noun:\",lem.lemmatize(\"rocks\"))\n","print(\"thought as noun:\",lem.lemmatize(\"thought\"))\n","\n","# lemmatize as verbs\n","print(\"rocks as verb:,\",lem.lemmatize(\"rocks\",pos =\"v\"))\n","print(\"thought as verb:,\",lem.lemmatize(\"thought\",pos =\"v\"))\n","print(\"played as verb:,\",lem.lemmatize(\"played\",pos =\"v\"))\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VKlTB7TBgJEA","executionInfo":{"status":"ok","timestamp":1717223993229,"user_tz":-330,"elapsed":1836,"user":{"displayName":"naimu samad","userId":"06085924539137588202"}},"outputId":"2b1a18ac-d88b-4eb5-9e5c-66933d190a60"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["rocks as noun: rock\n","thought as noun: thought\n","rocks as verb:, rock\n","thought as verb:, think\n","played as verb:, play\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"YNvGVW0AeIfk"},"execution_count":null,"outputs":[]}]}